csvURL = "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
?download.file
download.file( url = csvURL, destfile = "bspeed.csv", method = 'auto' )
df = read.csv( "bspeed.csv" )
getwd()
library( xlsx )
install.packages("xlsx")
library( xlsx )
library( rJava )
library(XML)
install.packages("XML")
library(XML)
xmlURL = "http://www.w3schools.com/xml/simple.xml"
xmlDoc = xmlTreeParse( xmlURL, useInternalNodes = TRUE )
rootNode = xmlRoot(xmlDoc)
xmlName( rootNode )
names( rootNode )
rootNode[[1]]
rootNode[[1]][[1]]
rootNode["food"]
rootNode["food"]["name"]
rootNode["food"]["food"]
rootNode["food"]["food"]["name"]
rootNode["food"]["food"][[1]]
rootNode["food"]["food"]["food"]
rootNode[["food"]]
rootNode[["food"]][["name"]]
xmlSApply( rootNode, xmlValue )
install.packageS("XPath")
install.packages("XPath")
install.packages("xpath")
xpathSApply( rootNode, "//name", xmlValue )
xpathSApply( rootNode, "//price", xmlValue )
hURL = "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
hDoc = htmlTreeParse( hURL, useInternalNodes = TRUE )
score = xpathSApply( hDoc, "//li[@class='score']", xmlValue )
team = xpathSApply( hDoc, "//li[@class='team-name']", xmlValue )
score
names(hDoc)
hURL = "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
hDoc = htmlTreeParse( hURL, useInternalNodes = TRUE )
names(hDoc)
hDoc[[1]]
install.packages("jsonlite")
library(jsonlite)
jsonData = fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
names( jsonData$owner )
View(jsonData)
jsonData$owner$login
install.packages("data.table")
library(data.table)
df = data.frame( x = rnorm(9), y = rep((c("a","b","c"), each = 3), ), z = rnorm(9) )
df = data.frame( x = rnorm(9), y = rep( c("a","b","c"), each = 3), ), z = rnorm(9) )
df = data.frame( x = rnorm(9), y = rep( c("a","b","c"), each = 3), z = rnorm(9) )
head(df, 3 )
dt = data.table( x = rnorm(9), y = rep( c("a","b","c"), each = 3), z = rnorm(9) )
head(dt, 3)
tables()
dt[2,]
dt[ dt$y == "a" ]
dt( c(2,3) )
dt[ c(2,3) ]
df[ c(2,3) ]
{ x = 1, y = 2 }
{ x = 1 y = 2 }
{
x = 1
y = 2
}
k = { print(10); 5 }
print(k)
dt[, list( mean(x), sum(z) ) ]
dt[ , table(y) ]
dt[, w := z^2 ] # Add col "w" that gets z squared
dt
dt[ , m := { tmp <- (x+z); log2(tmp+5) } ]
dt
dt[ , a := x > 0 ] # New col "a" stores rows where x is greater than 0
dt
dt[,b := mean( x + w ), by = a ]
dt
set.seed(123)
dt2 = data.table( x = sample( letters[1:3], 1E5, TRUE ) )
dt2[, .N, by=x ]
dt = data.table( x = rep( c("a","b","c"), each = 100 )m y = rnorm(100) )
dt = data.table( x = rep( c("a","b","c"), each = 100 ), y = rnorm(100) )
setkey( dt, x )
head( dt['a'] )
head( dt['a'], 20 )
rm( list = ls() )
dt1 = data.table( x = c('a', 'a', 'b', 'dt1' ), y = 1:4 )
dt2 = data.table( x = c( 'a', 'b'm 'dt2' ), z = 5:7 )
dt2 = data.table( x = c( 'a', 'b', 'dt2' ), z = 5:7 )
setkey( dt1, x ); setkey( dt2, x )
merge( dt1, dt2 )
dt1
dt2
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
rm( list = ls() )
fURL = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file( fURL, destfile = "quiz1q1.csv" )
df <- read.csv( "quiz1q1.csv" )
names( df )
sum( df$VAL > 24 )
View(df)
sum( df$VAL[ !is.na( df$VAL ) ] > 24 )
dfVal = df$VAL
head( dfVal )
dfVal[ !is.na( dfVal ) ]
dfVal = dfVal[ !is.na( dfVal ) ]
sum( dfVal == 24 )
sum( df$VAL[ !is.na( df$VAL ) ] == 24 )
rm() dfVal )
rm( "dfVal" )
install.packages( "rjava" )
install.packages( "rJava" )
library( rJava )
library( rJava )
library( xlsx )
setwd( "week1_quiz" )
download.file( "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx", destfile = "natural_gas_acq.xlsx" )
df <- read.xlsx( "natural_gas_acq.xlsx", sheetIndex = 1, header = TRUE, colIndex = 7:15, rowIndex = 18:23 )
df <- read.xlsx( "natural_gas_acq.xlsx", sheetIndex = 1, header = TRUE )
rm( "df" )
fp = "getdata-data-DATA.gov_NGAP.xlsx"
df <- read.xlsx( fp, sheetIndex = 1, header = TRUE, colIndex = 7:15, rowIndex = 18:23 )
sum( df$Zip * dat$Ext, na.rm = T )
sum( df$Zip * df$Ext, na.rm = T )
rm( "df" )
fp = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file( fp, destfile = "baltimore_restaurants.xml" )
library( XML )
xmlDoc = xmlTreeParse( fp, useInternalNodes = TRUE )
xmlDoc = xmlTreeParse( "baltimore_restaurants.xml", useInternalNodes = TRUE )
rootNode = xmlRoot(xmlDoc)
xpathSApply( rootNode, "//zipcode", xmlValue )
r = xpathSApply( rootNode, "//zipcode", xmlValue )
sum( r == 21231 )
rm( list = ls() )
fp = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file( fp, destfile = "am_community_survey.csv" )
DT = fread( "am_community_survey.csv" )
View(DT)
class( DT$pwgtp15 )
mean( DT$pwgtp15 )
system.time( sapply(split(DT$pwgtp15,DT$SEX),mean) )
sapply(split(DT$pwgtp15,DT$SEX),mean)
system.time( sapply(split(DT$pwgtp15,DT$SEX),mean) )
system.time( mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15) )
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
system.time( { mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15) } )
system.time( mean(DT$pwgtp15,by=DT$SEX) )
mean(DT$pwgtp15,by=DT$SEX)
DT[,mean(pwgtp15),by=SEX]
system.time( DT[,mean(pwgtp15),by=SEX] )
library(RMySQL)
hg19 <- dbConnect(
MySQL(),
user = "genome",
host = "genome-mysql.cse.ucsc.edu",
db   = "hg19"
)
tables <- dbListTables( hg19 )
length( tables )
tables[1:5]
dbListFields( hg19, "affyU133Plus2" )
dbGetQuery( hg19, "SELECT count(*) FROM affyU133Plus2" )
affyData = dbReadTable( hg19, "affyU133Plus2" )
head( affyData[,1:8] )
q = dbSendQuery( hg19, "SELECT * FROM affyU133Plus2 WHERE misMatches between 1 and 3" )
affyMis = fetch(q)
quantile( affyMis$misMatches )
affyMisSmall = fetch( q, n = 10 ) # Limit to 10 rows
dbClearResult( q )
dim( affyMisSmall )
dbDisconnect( hg19 )
source( “http://bioconductor.org/biocLite.R” )
biocLite("rhdf5")
source( "http://bioconductor.org/biocLite.R" )
biocLite("rhdf5")
library(rhdf5)
created = h5createFile("example.h5")
created
created = h5createGroup( "example.h5", "g1" )
created = h5createGroup( "example.h5", "g2" )
created = h5createGroup( "example.h5", "g1/sg1" )
h5ls( "example.h5" )
A = matrix( 1:10, nr = 5, nc = 2 )
h5write( A, "example.h5", "g1/A" ) # Write matrix content to new subgroup A
B = array( seq( 0.1, 2.0, by = 0.1 ), dim = c(5,2,2) )
attr(B, "scale" ) = "liter"
h5write( B, "example.h5", "g1/sg1/B" ) # Write array to new sub-subgroup
h5ls( "example.h5" )
df = data.frame(
1L:5L,
seq(0,1, length.out = 5 ),
c( "ab", "cde", "fghi", "a", "s" ),
stringsAsFactors = FALSE
)
h5write( "example.h5", "df" )
h5ls( "example.h5" )
h5write( df, "example.h5", "df" )
h5ls( "example.h5" )
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readline(con)
close(con)
htmlCode
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
con
htmlCode = readLines(con)
con = url("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readline(con)
htmlCode = readline(con)
con
con = url("https://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
con
rm( list = ls() )
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
con
htmlCode = readline(con)
htmlCode = readLines(con)
htmlCode
close(con)
webAddress = "http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en"
library(XML)
html = htmlTreeParse( webAddress, useInternalNodes = TRUE )
xpathSApply( html, "//title", xmlValue )
library(httr)
html2      = GET( webAddress )
content2   = content( html2, as = "TEXT" )
parsedHtml = htmlParse( content2, asText = TRUE )
xpathSApply( parsedHtml, "//title", xmlValue )
html2      = GET( webAddress )
content2   = content( html2, as = "TEXT" )
content2   = content( html2, as = "text" )
parsedHtml = htmlParse( content2, asText = TRUE )
xpathSApply( parsedHtml, "//title", xmlValue )
pg1 = GET( “http://httpbin.org/basic-auth/user/passwd” )
pg1 = GET( "http://httpbin.org/basic-auth/user/passwd” )
""
""
pg1 = GET( "http://httpbin.org/basic-auth/user/passwd" )
pg1
pg2 = GET(
"http://httpbin.org/basic-auth/user/passwd",
authenticate( "user", "passwd" )
)
pg2
names(pg2)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app(
"github",
key = "b9ec8cdba8b0f08349ce",
secret = "98d7becb7dc6192ffa57e027b6f1dff6d7b46075"
)
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
gtoken <- config(token = github_token)
req <- GET("https://api.github.com/users/jtleek/repos", gtoken)
stop_for_status(req)
content(req)
rm( list = ls() )
download.file( "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", "acs.csv" )
read.csv( "acs.csv" )
df = read.csv( "acs.csv" )
install.packages( "sqldf" )
sqldf("select pwgtp1 from acs where AGEP < 50")
library( "sqldf" )
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select pwgtp1 from df where AGEP < 50")
View(df)
sqldf("select distinct AGEP from acs")
sqldf("select distinct AGEP from df")
rm( list = ls() )
library(httr)
h = GET( "http://biostat.jhsph.edu/~jleek/contact.html" )
html = htmlTreeParse( "http://biostat.jhsph.edu/~jleek/contact.html", useInternalNodes = TRUE )
html[[10]]
html
html[10]
class(html)
?htmlParse
lines = strsplit( html, "\n" )
lines = strsplit( html, " " )
lines = strsplit( html, "\m" )
lines = strsplit( as.character( html ), "\m" )
lines = strsplit( as.character( html ), "\n" )
h
h$content
h$handle
xpathSApply( html, "//li[10]", xmlValue )
s = '<link rel="stylesheet" href="images/PixelGreen.css" type="text/css">'
nchar(s)
s = '<meta name="Robots" content="index,follow">'
nchar(s)
s2 = '(function() {'
nchar(s2)
s2 = "    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';"
nchar(s2)
s3 = '<div id="header"><div id="header-content">'
nchar(s3)
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
html[[10]]
html[10]
htmlCode[10]
nchar( htmlCode[10] )
nchar( htmlCode[20] )
nchar( htmlCode[30] )
nchar( htmlCode[100] )
x <- read.fwf( file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for") )
?read.fwf
dataWidths = c("17JAN1990", "24.2-0.3", "25.3-0.3", "26.5-0.1", "28.6 0.3")
widths = sapply( dataWidths, nchar )
x <- read.fwf( file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"), widths = widths )
sum(x$V4)
dataWidths = c("17JAN1990", "24.2","0.3", "25.3", "0.3", "26.5","0.1", "28.6","0.3" )
widths = sapply( dataWidths, nchar )
x <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip = 4,
widths = widths
)
sum(x$V4)
widths
widths = unlist( widths, use.names = FALSE )
widths
w = (9,4,3,4,3,4,3,4,3)
w = c(9,4,3,4,3,4,3,4,3)
x <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip = 4,
widths = w
)
x <- read.fwf(
file=url("https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"),
skip=4,
widths=c(12, 7, 4, 9, 4, 9, 4, 9, 4)
)
sum(x$V4)
rm( list = ls() )
set.seed( 13435 )
X = data.frame( "var1" = sample(1:5), "var2" = sample(6:10), "var3" = sample(11:15) )
X <- X[ sample(1:5),]; X$var2[ c(1,3) ] = NA
X
library( plyr )
arrange( X, var1 )
Y = cbind( X, rnorm(5) )
Y
names( Y ) = c( names(X), "var5" )
Y
if ( ! file.exists("./data") ) { dir.create( "./data" ) }
fileURL = "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file( fileURL, destfile = "./data/restaurants.csv" )
restData = read.csv("./data/restaurants.csv")
rm( list = c("X","Y"))
head( restData )
summary( df )
summary( restData )
table( restData$councilDistrict, restData$zipCode )
table( restData$councilDistrict, restData$zipCode )[1:10]
table( restData$councilDistrict, restData$zipCode )[,1:10]
any( is.na( restData$councilDistrict ) )
all( restData$zipCode > 0 )
table( restData$zipCode %in% c( "21212", "21213" ) )
library(datasets)
data("UCBAdmissions")
df = as.data.frame( UCBAdmissions )
summary( df )
xt <- xtabs( Freq ~ Gender + Admit, data = df )
xt
data( "warpbreaks" )
df2 = as.data.frame( warpbreaks )
df2$replicate = rep( 1:9, len = 54 )
ftable( df2 )
xt = xtabs( breaks ~., data = warpbreaks )
ftable( xt )
xt = xtabs( breaks ~., data = df2 )
ftable( xt )
fakeData = rnorm(1e5)
object.size( fakeData )
print( object.size(fakeData), units = "Mb" )
x = c( 1, 3, 8, 25, 100 ); seq( along = x )
restData$zipGroups = cut( restData$zipCode, breaks = quantile( restData$zipCode ) )
?cut
head( restData$zipGroups )
table( restData$zipGroups )
table( restData$zipGroups )
install.packages("Hmisc")
library( Hmisc )
restData$zipGroups = cut2( restData$zipCode, g = 4 ) # 4 equal groups
table( restData$zipGroups )
?mutate
install.packages("reshape2")
library(reshape2)
library(datasets)
data("mtcars")
mtcars = as.data.frame(mtcars)
head(mtcars)
?melt
mtcars$carname = rownames( mtcars )
carMelt = melt( mtcars, id = c("carname", "gear", "cyl" ), measure.vars = c( "mpg", "hp" ) )
head( carMelt, n = 3 )
tail( carMelt, n = 3 )
cylData = dcast( carMelt, cyl ~ variable )
head( cylData )
cylData
cylData = dcast( carMelt, cyl ~ variable, mean )
cylData
?tapply
data("InsectSprays")
is = as.data.frame(InsectSprays)
head(is)
tapply( is$count, is$spray, sum )
library( dplyr )
ddply( is, .(spray), summarize, sum = sum(count) )
library(plyr)
ddply( is, .(spray), summarize, sum = sum(count) )
